{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re #gpt suggested\n",
        "\n",
        "df = pd.read_csv(\"/content/train.csv\")\n",
        "\n",
        "#drop dupes\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "#null strings to nan b4 parsing\n",
        "for col in ['Mileage','Engine','Power','New_Price']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].replace(['null','Null','NULL','',' '], np.nan)\n",
        "\n",
        "#A\n",
        "#missing counts\n",
        "missing_before = df.isna().sum()\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Don’t impute New_Price due to heavy missingness (document this choice)\n",
        "if 'New_Price' in numeric_cols:\n",
        "    numeric_cols.remove('New_Price')\n",
        "\n",
        "for col in numeric_cols:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "missing_after = df.isna().sum()"
      ],
      "metadata": {
        "id": "GQmfZasSs-UM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) handling missing values\n",
        "\n",
        "\n",
        "in this step i looked for missing values in the dataset using the isna() function. several columns like mileage, engine, power, and seats had some missing values. the new_price column had many missing values. to fix this, i filled the numeric columns with their median values because the median is not affected much by extreme numbers. for text columns, i filled them with the most common value (the mode). i left the new_price column as it was because most of its values were missing, and filling it could make the data unrealistic. this step made sure that there were no empty cells left that could cause problems later when doing analysis."
      ],
      "metadata": {
        "id": "LBsWAl56u6Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#B\n",
        "def extract_number(x):\n",
        "    \"\"\"Return first float-like number from a string or NaN.\"\"\"\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    m = re.search(r'(\\d+(\\.\\d+)?)', str(x))\n",
        "    return float(m.group(1)) if m else np.nan\n",
        "\n",
        "df['Mileage'] = df['Mileage'].apply(extract_number)\n",
        "df['Engine'] = df['Engine'].apply(extract_number)\n",
        "df['Power'] = df['Power'].apply(extract_number)\n",
        "def parse_new_price(x): #GPT assisted\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    s = str(x).strip()\n",
        "    num = extract_number(s)\n",
        "    if num is None or np.isnan(num):\n",
        "        return np.nan\n",
        "    if 'Cr' in s or 'crore' in s.lower():\n",
        "        return num * 100.0   # 1 Cr = 100 Lakh\n",
        "    # default assume Lakh\n",
        "    return num\n",
        "\n",
        "df['New_Price'] = df['New_Price'].apply(parse_new_price)"
      ],
      "metadata": {
        "id": "oTKK_G6ithXg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) removing units\n",
        "\n",
        "\n",
        "some columns in the dataset contained both numbers and words, like “19.67 kmpl” or “1582 cc.” python treats these as text, which makes it hard to do calculations. i removed the extra text and kept only the numeric part using regular expressions. i also converted the new_price column from “lakh” and “cr” (crore) units into plain numbers by changing 1 crore into 100 lakh. after this cleaning, all the columns like mileage, engine, power, and new_price were stored as numbers, which makes them easier to analyze later."
      ],
      "metadata": {
        "id": "VsgCfM74vSha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#C GPT assisted\n",
        "cols_to_encode = [c for c in ['Fuel_Type','Transmission'] if c in df.columns]\n",
        "df = pd.get_dummies(df, columns=cols_to_encode, drop_first=True)"
      ],
      "metadata": {
        "id": "EIdghY0qtkol"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) encoding categorical variables\n",
        "\n",
        "the dataset had some columns with text values, like fuel_type and transmission. since most analysis methods and machine learning models work better with numbers, i changed these text columns into numeric columns using one-hot encoding. this created new columns like fuel_type_petrol and transmission_manual, which show 1 or 0 depending on the category. now the dataset is fully numeric and easier to use for statistical work or prediction models."
      ],
      "metadata": {
        "id": "BXEEf6uSvWnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#D\n",
        "df['car_age'] = 2025 - df['Year']"
      ],
      "metadata": {
        "id": "v6JQc5WxuBw9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) creating a new feature\n",
        "\n",
        "\n",
        "to add more useful information to the dataset, i created a new column called car_age. i calculated it by subtracting the year of the car from the current year (2025). this new feature helps us understand how old each car is, which is an important factor that affects the price of a used car."
      ],
      "metadata": {
        "id": "akHaAunrvjvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#E\n",
        "keep_cols = [c for c in ['Name','Location','Year','Kilometers_Driven','Mileage',\n",
        "                         'Engine','Power','Seats','New_Price','Price','car_age',\n",
        "                         'Fuel_Type_Diesel','Fuel_Type_Petrol','Transmission_Manual'] if c in df.columns]\n",
        "cars_selected = df[keep_cols].copy()\n",
        "\n",
        "cars_filtered = cars_selected.loc[(cars_selected['car_age'] < 10) & (~cars_selected['Price'].isna())].copy()\n",
        "cars_filtered = cars_filtered.rename(columns={'Price': 'Used_Price_Lakh'})\n",
        "cars_filtered['Price_per_1000cc'] = cars_filtered['Used_Price_Lakh'] / cars_filtered['Engine'].replace(0, np.nan) * 1000\n",
        "cars_sorted = cars_filtered.sort_values(by='Used_Price_Lakh', ascending=False)\n",
        "\n",
        "summary_by_owner = (\n",
        "    df.groupby('Owner_Type', dropna=False)['Price']\n",
        "      .agg(mean_price='mean', median_price='median', n='count')\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "#GPT-assisted summart\n",
        "\n",
        "#cars_sorted.to_csv('cars_sorted.csv', index=False)\n",
        "#summary_by_owner.to_csv('summary_by_owner.csv', index=False)\n",
        "\n",
        "print(\"Missing before:\\n\", missing_before)\n",
        "print(\"\\nMissing after (note New_Price intentionally left as-is):\\n\", missing_after)\n",
        "print(\"\\nGroup summary by Owner_Type:\\n\", summary_by_owner.head())\n",
        "print(\"\\nPreview cleaned rows:\\n\", cars_sorted.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5WLuvD5uOE_",
        "outputId": "8c42a681-c5b2-4ba1-f8fa-d91a9c2e2279"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing before:\n",
            " Name                    0\n",
            "Location                0\n",
            "Year                    0\n",
            "Kilometers_Driven       0\n",
            "Fuel_Type               0\n",
            "Transmission            0\n",
            "Owner_Type              0\n",
            "Mileage                 2\n",
            "Engine                 36\n",
            "Power                  36\n",
            "Seats                  38\n",
            "New_Price            5032\n",
            "Price                   0\n",
            "dtype: int64\n",
            "\n",
            "Missing after (note New_Price intentionally left as-is):\n",
            " Name                 0\n",
            "Location             0\n",
            "Year                 0\n",
            "Kilometers_Driven    0\n",
            "Fuel_Type            0\n",
            "Transmission         0\n",
            "Owner_Type           0\n",
            "Mileage              0\n",
            "Engine               0\n",
            "Power                0\n",
            "Seats                0\n",
            "New_Price            0\n",
            "Price                0\n",
            "dtype: int64\n",
            "\n",
            "Group summary by Owner_Type:\n",
            "        Owner_Type  mean_price  median_price     n\n",
            "0           First   10.105076         5.990  4811\n",
            "1  Fourth & Above    3.415000         3.125     8\n",
            "2          Second    7.839719         4.500   925\n",
            "3           Third    5.348058         2.950   103\n",
            "\n",
            "Preview cleaned rows:\n",
            "                                              Name    Location  Year  \\\n",
            "3952  Land Rover Range Rover 3.0 Diesel LWB Vogue   Hyderabad  2017   \n",
            "1457              Land Rover Range Rover Sport SE       Kochi  2019   \n",
            "1917                           BMW 7 Series 740Li  Coimbatore  2018   \n",
            "\n",
            "      Kilometers_Driven  Mileage  Engine  Power  Seats  New_Price  \\\n",
            "3952              25000    13.33  2993.0  255.0    5.0     230.00   \n",
            "1457              26013    12.65  2993.0  255.0    5.0     139.00   \n",
            "1917              28060    12.05  2979.0  320.0    5.0       4.78   \n",
            "\n",
            "      Used_Price_Lakh  car_age  Fuel_Type_Petrol  Transmission_Manual  \\\n",
            "3952           160.00        8             False                False   \n",
            "1457            97.07        6             False                False   \n",
            "1917            93.67        7              True                False   \n",
            "\n",
            "      Price_per_1000cc  \n",
            "3952         53.458069  \n",
            "1457         32.432342  \n",
            "1917         31.443437  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) data wrangling operations\n",
        "\n",
        "\n",
        "in this part i used basic data manipulation steps. first, I selected only the columns that were most useful for analysis. then, I filtered the data to include only cars that were less than ten years old. i renamed the price column to used_price_lakh to make it clearer. i created a new column called price_per_1000cc to show how much each car costs for every 1000 cc of engine size. next, i arranged the rows so that the most expensive cars appear first. finally, i grouped the data by owner_type and calculated the average, median, and number of cars in each group. these steps helped me organize and summarize the dataset so it became cleaner and easier to understand"
      ],
      "metadata": {
        "id": "5Mily5OfwRoo"
      }
    }
  ]
}